{
  "settings.title": "Settings",

  "settings.asr.title": "Transcription (ASR)",
  "settings.asr.description": "Speech-to-text engine settings",
  "settings.asr.help.mlx": "MLX Whisper runs on Apple Silicon GPU (Metal). No CPU option available.",
  "settings.asr.help.cloud": "Cloud engines handle speaker detection automatically.",

  "settings.diarization.title": "Speaker Diarization",
  "settings.diarization.description": "Identify who said what in recordings",
  "settings.diarization.device.label": "Compute Device",
  "settings.diarization.device.auto": "Auto - Detect best device (GPU preferred)",
  "settings.diarization.device.gpu": "GPU (MPS) - Faster, may heat up",
  "settings.diarization.device.cpu": "CPU - Stable, slower, more methods",
  "settings.diarization.device.help": "MacBook Air users: Consider CPU for long files to avoid thermal throttling.",
  "settings.diarization.method.label": "Method",
  "settings.diarization.method.none": "None - No diarization",
  "settings.diarization.method.fast": "Fast - Pyannote speaker detection",
  "settings.diarization.method.accurate": "Accurate - WhisperX word-level (CPU only)",
  "settings.diarization.method.help.cpu": "Fast: Quick detection. Accurate: Word-level alignment (slower, CPU only).",
  "settings.diarization.method.help.gpu": "Fast: Quick speaker detection on GPU.",
  "settings.diarization.speakers.min": "Min Speakers",
  "settings.diarization.speakers.max": "Max Speakers",
  "settings.diarization.token.label": "HuggingFace Token",
  "settings.diarization.token.help": "Required for diarization. Get token from huggingface.co/settings/tokens",

  "settings.whisper.title": "Whisper Quality Settings",
  "settings.whisper.description": "Prevent hallucinations like \"Subtitles by...\" during silence",
  "settings.whisper.noSpeech.label": "No Speech Threshold",
  "settings.whisper.noSpeech.range": "Range: 0.0 - 1.0",
  "settings.whisper.noSpeech.default": "Default: 0.6",
  "settings.whisper.noSpeech.help": "If Whisper thinks there's no speech in a segment with probability above this threshold, the segment is skipped.",
  "settings.whisper.noSpeech.helpHigh": "Higher (0.7-0.9) = fewer hallucinations, but may skip quiet speech",
  "settings.whisper.noSpeech.helpLow": "Lower (0.3-0.5) = more text, but more garbage",
  "settings.whisper.logProb.label": "Log Probability Threshold",
  "settings.whisper.logProb.range": "Range: -10.0 - 0.0 (always negative!)",
  "settings.whisper.logProb.default": "Default: -1.0",
  "settings.whisper.logProb.help": "Average model confidence in segment. Closer to 0 = more confident.",
  "settings.whisper.logProb.helpHigh": "Closer to 0 (-0.5) = only confident segments, may lose text",
  "settings.whisper.logProb.helpLow": "Further from 0 (-2.0) = more text, more hallucinations",
  "settings.whisper.compression.label": "Compression Ratio Threshold",
  "settings.whisper.compression.range": "Range: 1.0 - 10.0",
  "settings.whisper.compression.default": "Default: 2.4",
  "settings.whisper.compression.help": "Filters repetitive/looping text (like \"yes yes yes yes yes\").",
  "settings.whisper.compression.helpLow": "Lower (1.5-2.0) = stricter repetition filter",
  "settings.whisper.compression.helpHigh": "Higher (3.0-5.0) = allows more repetitions",
  "settings.whisper.silence.label": "Hallucination Silence Threshold (sec)",
  "settings.whisper.silence.range": "Range: 0.5 - 30.0 seconds (or empty)",
  "settings.whisper.silence.default": "Default: 2.0",
  "settings.whisper.silence.placeholder": "Empty = disabled",
  "settings.whisper.silence.help": "Skips text that appears after a long pause (main hallucination filter!).",
  "settings.whisper.silence.helpLow": "Lower (0.5-1.0) = more aggressive, may cut real speech after pauses",
  "settings.whisper.silence.helpHigh": "Higher (3.0-5.0) = gentler, may pass short hallucinations",
  "settings.whisper.context.label": "Use Previous Context",
  "settings.whisper.context.enabled": "Enabled",
  "settings.whisper.context.disabled": "Disabled",
  "settings.whisper.context.help": "Uses previously recognized text as context for the next segment. Helps with consistency but can get stuck on errors. Recommended to leave enabled.",

  "settings.cloudAsr.title": "Cloud ASR Providers",
  "settings.cloudAsr.description": "Configure API keys for cloud transcription services",
  "settings.cloudAsr.assemblyai": "AssemblyAI",
  "settings.cloudAsr.deepgram": "Deepgram",
  "settings.cloudAsr.elevenlabs": "ElevenLabs Scribe",
  "settings.cloudAsr.yandex": "Yandex SpeechKit",

  "settings.llm.title": "LLM Post-Processing",
  "settings.llm.description": "AI-powered transcript cleanup and summarization",
  "settings.llm.provider.label": "Post-Processing Provider",
  "settings.llm.model.label": "Default Model",
  "settings.llm.legacy.label": "Default LLM Provider (Legacy)",
  "settings.llm.legacy.help": "Used by legacy features",
  "settings.llm.provider.gemini": "Google Gemini",
  "settings.llm.provider.openrouter": "OpenRouter",
  "settings.llm.model.gemini25flash": "Gemini 2.5 Flash",
  "settings.llm.model.gemini25flashLite": "Gemini 2.5 Flash Lite",
  "settings.llm.model.gemini3flashPreview": "Gemini 3 Flash Preview",
  "settings.llm.model.gpt4oMini": "GPT-4o Mini",
  "settings.llm.model.claude35sonnet": "Claude 3.5 Sonnet",
  "settings.llm.model.claude35haiku": "Claude 3.5 Haiku",
  "settings.llm.model.deepseekR1": "DeepSeek R1",
  "settings.llm.model.llama31": "Llama 3.1 70B",
  "settings.llm.model.gemini25flashViaOr": "Gemini 2.5 Flash (via OR)",

  "settings.insights.title": "AI Insights",
  "settings.insights.description": "Level 2 post-processing for extracting structured insights from transcripts",
  "settings.insights.help": "AI Insights extracts structured data like action items, decisions, and mindmaps from meeting transcripts."
}
